{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 980 Ti (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the ascii text and convert to lowercase\n",
    "filename = \"./data/alice_wonderland.txt\"\n",
    "raw_text = open(filename).read()\n",
    "raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mapping of unique characters to int, and a reverse mapping\n",
    "chars = sorted(list(set(raw_text)))\n",
    "char_to_int = dict((c, i) for i, c in enumerate(chars))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Characters  144373\n",
      "Total Unique Vocab  45\n"
     ]
    }
   ],
   "source": [
    "# summarize the loaded data\n",
    "num_chars = len(raw_text)\n",
    "num_vocab = len(chars)\n",
    "print(\"Total Characters \", num_chars)\n",
    "print(\"Total Unique Vocab \", num_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "# split into subsequences of fixed character length.\n",
    "# can also split data up by sentences. pad shorter ones. truncate longer ones.\n",
    "seq_len = 100\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, num_chars - seq_len, 1):\n",
    "    seq_in = raw_text[i:i + seq_len]\n",
    "    seq_out = raw_text[i + seq_len]\n",
    "    dataX.append([char_to_int[char] for char in seq_in])\n",
    "    dataY.append(char_to_int[seq_out])\n",
    "num_patterns = len(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "X = np.reshape(dataX, (num_patterns, seq_len, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize\n",
    "# LSTM uses sigmoid activation by default so needs range of 0 - 1\n",
    "X = X/float(num_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one hot encode the output variable\n",
    "y = np_utils.to_categorical(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the LSTM model\n",
    "# two LSTM layers with 256 memory units\n",
    "# dropout probability of 20\n",
    "# output layer is Dense layer using softmax activation function with ADAM optimizer\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load network weights with smallest loss value from previous training\n",
    "filename = \"./weights/weights-improvement-40-1.3063-twolayers.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed:\n",
      "\" \n",
      "\n",
      "the king turned pale, and shut his note-book hastily. ‘consider your\n",
      "verdict,’ he said to the jury \"\n"
     ]
    }
   ],
   "source": [
    "# pick a random seed\n",
    "start = np.random.randint(0, len(dataX) -1)\n",
    "pattern = dataX[start]\n",
    "print(\"Seed:\")\n",
    "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". ‘i must have to she bert wiine,’\n",
      "\n",
      "‘what a pueer to be as all ’ said the daterpillar.\n",
      "\n",
      "‘well, i should shink i must be a batce,’ said the duchess, ‘and the mosal of the sea- the duchess! the fuchess and the sea- the duchess and the sea- the fuchess said ‘it is the wayeng!’\n",
      "\n",
      "‘i don’t know what you do,’ said the daterpillar.\n",
      "\n",
      "‘well, i should shink i must be a batce,’ said the daterpillar.\n",
      "\n",
      "‘well, i should shink i meant with the rueen!’ said the duchess, ‘and the mosal of the sea- the duchess! the fuchess and the sea- the duchess and the sea- the fuchess said ‘it is the wayeng!’\n",
      "\n",
      "‘i don’t know what you do,’ said the daterpillar.\n",
      "\n",
      "‘well, i should shink i must be a batce,’ said the daterpillar.\n",
      "\n",
      "‘well, i should shink i meant with the rueen!’ said the duchess, ‘and the mosal of the sea- the duchess! the fuchess and the sea- the duchess and the sea- the fuchess said ‘it is the wayeng!’\n",
      "\n",
      "‘i don’t know what you do,’ said the daterpillar.\n",
      "\n",
      "‘well, i should shink i must be a batce,’ said the date\n",
      "Finished\n",
      "73.88552165052783\n"
     ]
    }
   ],
   "source": [
    "start = timeit.default_timer()\n",
    "\n",
    "# generate characters\n",
    "for i in range(1000):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x/float(num_vocab)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = np.argmax(prediction)\n",
    "    result = int_to_char[index]\n",
    "    seq_in = [int_to_char[value] for value in pattern]\n",
    "    sys.stdout.write(result)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]\n",
    "print(\"\\nFinished\")\n",
    "stop = timeit.default_timer()\n",
    "print(stop - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
